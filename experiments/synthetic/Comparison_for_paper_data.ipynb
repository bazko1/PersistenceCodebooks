{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation with splits from paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (50, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load diagrams\n",
    "data_path = \"./pd.mat\"\n",
    "data_mat = scipy.io.loadmat(data_path)\n",
    "data = data_mat[\"pds\"]\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "# y - labels - type of diagram [0-7]\n",
    "# We transpose to iterate over diagram list\n",
    "y = []\n",
    "for label, diagram_list in enumerate(data.T):\n",
    "    y += len(diagram_list) * [label]\n",
    "y = np.array(y)\n",
    "\n",
    "# data.T = 2d array of diagrams as row, column as type\n",
    "X = data.T.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits, these are indexes of points in X, matlab index from 1 (so we do -1)\n",
    "synth_splits = scipy.io.loadmat('./presplited/synthetic_splits.mat')\n",
    "test_set = synth_splits['testSets'] - 1\n",
    "train_set = synth_splits['trainSets'] - 1\n",
    "\n",
    "tt_pairs = np.array([np.array((train, test)) for train, test in zip(train_set, test_set)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: Model hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from preprocessing import *\n",
    "from persistence_bow import *\n",
    "from visualization import *\n",
    "from persistence_fv import *\n",
    "from experiments.utils import *\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from gudhi.representations.kernel_methods import SlicedWassersteinKernel\n",
    "from gudhi.representations.vector_methods import PersistenceImage\n",
    "from gudhi.representations.metrics import BottleneckDistance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function, constructs final pipeline and returns girdsearch for it\n",
    "def make_final_grid(estimator,\n",
    "                    param_grid,\n",
    "                    kernel=\"linear\",\n",
    "                    cv=tt_pairs,\n",
    "                    **kwargs):\n",
    "    new_param_grid = {f\"Model__{name}\" : values for name, values in param_grid.items()}\n",
    "    new_param_grid[\"Predictor__C\"] = [0.1, 1, 10]\n",
    "    \n",
    "    final_pipeline = Pipeline([\n",
    "        (\"Model\", estimator),\n",
    "        (\"Predictor\", SVC(kernel=kernel, max_iter=1e6))\n",
    "    ])\n",
    "    \n",
    "    return GridSearchCV(final_pipeline, new_param_grid, cv = cv, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBoW gridsearch\n",
    "pbow_gridsearch = make_final_grid(\n",
    "    estimator = PersistenceBow(KMeans(7, n_init=1, max_iter=100, random_state=42),\n",
    "                              sampler=RandomPDSampler(2500, random_state=42)),\n",
    "    param_grid = {\n",
    "        \"cluster__n_clusters\" : np.arange(10, 150, 15),\n",
    "        \"sampler__max_points\" : np.arange(1000, 10000, 2000),\n",
    "        \"sampler__weight_function\" : [const, linear]\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "#SPBoW gridsearch\n",
    "spbow_gridsearch = make_final_grid(\n",
    "    estimator = StablePersistenceBow(GaussianMixture(covariance_type=\"diag\", random_state=42),\n",
    "                              sampler=RandomPDSampler(2500, random_state=42)),\n",
    "    param_grid = {\n",
    "        \"mixture__n_components\" : np.arange(10, 200, 15),\n",
    "        \"sampler__max_points\" : np.arange(1000, 13000, 2000),\n",
    "        \"sampler__weight_function\" : [const, linear]\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "#PBoW gridsearch with grid sampler\n",
    "pbow_grid_gridsearch = make_final_grid(\n",
    "    estimator = PersistenceBow(KMeans(7, n_init=1, max_iter=100, random_state=42),\n",
    "                              sampler=GridPDSampler((10,10), 100, random_state=42)),\n",
    "    param_grid = {\n",
    "        \"cluster__n_clusters\" : np.arange(10, 150, 15),\n",
    "        \"sampler__max_points\" : [10, 50, 100, 200, 500],\n",
    "        \"sampler__grid_shape\" : [(5,5), (10,10), (15,15), (20,20), (40,40)],\n",
    "        \"sampler__weight_function\" : [const, linear]\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "#SPBoW gridsearch with grid sampler\n",
    "spbow_grid_gridsearch = make_final_grid(\n",
    "    estimator = StablePersistenceBow(GaussianMixture(covariance_type=\"diag\", random_state=42),\n",
    "                              sampler=GridPDSampler((10,10),100, random_state=42)),\n",
    "    param_grid = {\n",
    "        \"mixture__n_components\" : np.arange(10, 200, 15),\n",
    "        \"sampler__max_points\" : [10, 50, 100, 200, 500],\n",
    "        \"sampler__grid_shape\" : [(5,5), (10,10), (15,15), (20,20), (40,40)],\n",
    "        \"sampler__weight_function\" : [const, linear]\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "\n",
    "# Fisher_vector \n",
    "fisher_vector_gridsearch = make_final_grid(\n",
    "    PersistenceFV(sampler=RandomPDSampler(random_state=42)), \n",
    "    param_grid = {\n",
    "        \"gmm_clusters_number\" : np.arange(10, 200, 15),\n",
    "        \"sampler__max_points\" : np.arange(1000, 13000, 2000),\n",
    "        \"sampler__weight_function\" : [const, linear]},\n",
    "    n_jobs= - 1)\n",
    "\n",
    "# Fisher_vector with grid sampler\n",
    "fisher_vector_grid_gridsearch = make_final_grid(\n",
    "    PersistenceFV(sampler=GridPDSampler((10,10), 100,random_state=42)), \n",
    "    param_grid = {\n",
    "        \"gmm_clusters_number\" : np.arange(10, 200, 15),\n",
    "        \"sampler__max_points\" : [10, 50, 100, 200, 500],\n",
    "        \"sampler__grid_shape\" : [(5,5), (10,10), (15,15), (20,20), (40,40)],\n",
    "        \"sampler__weight_function\" : [const, linear]},\n",
    "    n_jobs= - 1)\n",
    "\n",
    "\n",
    "\n",
    "models_to_test = {\n",
    "    \"PBoW\" : pbow_gridsearch, \n",
    "    \"PBoW_Grid\" : pbow_grid_gridsearch,\n",
    "    \"SPboW\" : spbow_gridsearch,\n",
    "    \"SPBoW_Grid\" : spbow_grid_gridsearch,\n",
    "    \"FisherVector\": fisher_vector_gridsearch,\n",
    "    \"FisherVector_Grid\": fisher_vector_grid_gridsearch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBoW\n",
      "Loaded from file\n",
      "PBoW_Grid\n",
      "Loaded from file\n",
      "SPboW\n",
      "Loaded from file\n",
      "SPBoW_Grid\n",
      "Loaded from file\n",
      "FisherVector\n",
      "Loaded from file\n",
      "FisherVector_Grid\n",
      "Loaded from file\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization\n",
    "for name, grid in models_to_test.items():\n",
    "    print(name)\n",
    "    grid_path = f\"grid/{name}.dill\"\n",
    "    \n",
    "    out = load(grid_path)\n",
    "    if out:\n",
    "        print(\"Loaded from file\")\n",
    "        models_to_test[name] = out\n",
    "    else:\n",
    "        grid.verbose = 10\n",
    "        grid.fit(X, y)\n",
    "        save(grid, grid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded results: PBoW_Grid\n",
      "Loaded results: SPboW\n",
      "Loaded results: SPBoW_Grid\n",
      "Loaded results: PBoW\n",
      "Loaded results: FisherVector\n",
      "Loaded results: FisherVector_Grid\n"
     ]
    }
   ],
   "source": [
    "#Grid computation\n",
    "grid_path = f\"./grid/\"\n",
    "cv_path = f\"./cv/\"\n",
    "\n",
    "for filename in os.listdir(grid_path):\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    grid = load(os.path.join(grid_path, filename))\n",
    "    results = load(os.path.join(cv_path, filename))\n",
    "    \n",
    "    if not results:\n",
    "        print(\"Computing\", name)\n",
    "        model = grid.best_estimator_\n",
    "        results = cross_validate(model, X, y, cv=tt_pairs, n_jobs=-1, verbose=10)\n",
    "        save(results, os.path.join(cv_path, f\"{name}.dill\"))\n",
    "    else:\n",
    "        print(f\"Loaded results: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPBoW_Grid Test set score:\n",
      " 0.9800000000000001 \n",
      "\n",
      "FisherVector_Grid Test set score:\n",
      " 0.9714285714285715 \n",
      "\n",
      "PBoW Test set score:\n",
      " 0.9714285714285715 \n",
      "\n",
      "FisherVector Test set score:\n",
      " 0.9657142857142856 \n",
      "\n",
      "SPboW Test set score:\n",
      " 0.9771428571428572 \n",
      "\n",
      "PBoW_Grid Test set score:\n",
      " 0.9742857142857144 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./cv\"\n",
    "for filename in os.listdir(base_path):\n",
    "    path = os.path.join(base_path, filename)\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    result = load(path)\n",
    "    print(name, \"Test set score:\\n\", result[\"test_score\"].mean(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
