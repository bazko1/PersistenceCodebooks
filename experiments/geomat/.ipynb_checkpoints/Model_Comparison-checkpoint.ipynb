{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1, 19)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./exp03_pds.mat\"\n",
    "data_mat = scipy.io.loadmat(data_path)\n",
    "data = data_mat[\"pds\"]\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.ravel()\n",
    "\n",
    "y = []\n",
    "for label, diagram in enumerate(data):\n",
    "    diagram = diagram.ravel()\n",
    "    y += len(diagram) * [label]\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.concatenate(data)\n",
    "X = np.concatenate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = \"./geomat_splits.mat\"\n",
    "splits_mat = scipy.io.loadmat(splits_path)\n",
    "trainSets = splits_mat[\"trainSet\"].ravel() - 1\n",
    "testSets = splits_mat[\"testSet\"].ravel() - 1\n",
    "\n",
    "premade_splits = np.array([np.array((testSet.ravel(), trainSet.ravel())) \n",
    "                           for testSet, trainSet in zip(trainSets, testSets)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison\n",
    "## First step: Model hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessing import *\n",
    "from persistent_bow import *\n",
    "from visualization import *\n",
    "from experiments.utils import *\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "from gudhi.representations.preprocessing import BirthPersistenceTransform, DiagramScaler\n",
    "from gudhi.representations.kernel_methods import SlicedWassersteinKernel\n",
    "from gudhi.representations.vector_methods import PersistenceImage\n",
    "from gudhi.representations.metrics import BottleneckDistance\n",
    "\n",
    "#Fast hack to make SlicedWassersteinKernel scikit-compliant\n",
    "setattr(SlicedWassersteinKernel, \"get_params\",\n",
    "        lambda self, deep: {\n",
    "            \"bandwidth\":self.bandwidth,\n",
    "            \"num_directions\" : self.sw_.num_directions\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "fold = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "splits = premade_splits#np.array([split for split in fold.split(X, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function, constructs final pipeline and returns girdsearch for it\n",
    "def make_final_grid(estimator, param_grid, kernel=\"linear\", *args, **kwargs ):\n",
    "    new_param_grid = {f\"Model__{name}\" : values for name, values in param_grid.items()}\n",
    "    new_param_grid[\"Predictor__C\"] = [0.1, 1, 10]\n",
    "    \n",
    "    final_pipeline = Pipeline([\n",
    "        (\"Model\", estimator),\n",
    "        (\"Predictor\", SVC(kernel=kernel, max_iter=1e4))\n",
    "    ])\n",
    "    \n",
    "    return GridSearchCV(final_pipeline, new_param_grid, cv = splits, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight functions\n",
    "\n",
    "def const(x):\n",
    "    return 1\n",
    "\n",
    "def linear(x):\n",
    "    return x[1]\n",
    "\n",
    "def pow2(x):\n",
    "    return x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBoW gridsearch\n",
    "pbow_gridsearch = make_final_grid(\n",
    "    estimator = PersistenceBow(KMeans(7, n_init=1, max_iter=100, random_state=42),\n",
    "                              sampler=RandomPDSampler(2500, random_state=42),\n",
    "                              scaler=DiagramScaler(use=True, \n",
    "                                                   scalers=[\n",
    "                                                      ((0,), MinMaxScaler(copy=False)),\n",
    "                                                      ((1,), MinMaxScaler(copy=False))])),\n",
    "    param_grid = {\n",
    "        \"cluster__n_clusters\" : np.arange(10, 200, 10),\n",
    "        \"sampler__max_points\" : np.arange(1000, 13000, 1000),\n",
    "        \"sampler__weight_function\" : [const, linear, pow2]\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "#SPBoW gridsearch\n",
    "spbow_gridsearch = make_final_grid(\n",
    "    estimator = StablePersistenceBow(GaussianMixture(random_state=42),\n",
    "                              sampler=RandomPDSampler(2500, random_state=42)),\n",
    "    param_grid = {\n",
    "        \"mixture__n_components\" : np.arange(10, 200, 10),\n",
    "        \"sampler__max_points\" : np.arange(1000, 13000, 1000),\n",
    "        \"sampler__weight_function\" : [const, linear, pow2]\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# PBOW with KMeans from VLFeat # TODO: This is Vl kmeans are 2 functions only\n",
    "# We need to wrap it with something what fits fit, transform API\n",
    "# pbow_on_stereoids = pbow_pipeline = Pipeline([\n",
    "#     (\"pbow\",  PersistentBow(Vlkmeans(7,2), sampler=RandomPDSampler(2500)))\n",
    "# ])\n",
    "\n",
    "\n",
    "#SlicedWassersteinKernel gridsearch (without using it as kernel)\n",
    "swk_gridsearch = make_final_grid(\n",
    "    estimator = SlicedWassersteinKernel(),\n",
    "    param_grid = {\n",
    "        \"bandwidth\" : [0.05, 0.1, 0.25, 0.5, 1, 1.5, 2],\n",
    "        \"num_directions\" : [5, 10, 15, 20, 25]\n",
    "    },\n",
    "    n_jobs = -1    \n",
    ")\n",
    "\n",
    "#SlicedWassersteinKernel gridsearch (using it as kernel)\n",
    "swk_ker_gridsearch = make_final_grid(\n",
    "    estimator = SlicedWassersteinKernel(),\n",
    "    param_grid = {\n",
    "        \"bandwidth\" : [0.05, 0.1, 0.25, 0.5, 1, 1.5, 2],\n",
    "        \"num_directions\" : [5, 10, 15, 20, 25]\n",
    "    },\n",
    "    kernel=\"precomputed\",\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "#BottleneckDistance gridsearch\n",
    "bd_gridsearch = make_final_grid(\n",
    "    estimator = BottleneckDistance(),\n",
    "    param_grid = {\n",
    "        \"epsilon\" : [1e-8, None]\n",
    "    },\n",
    "    n_jobs = -1  \n",
    ")\n",
    "\n",
    "#PersistenceImage gridsearch\n",
    "pi_gridsearch = make_final_grid(\n",
    "    estimator = PersistenceImage(),\n",
    "    param_grid = {\n",
    "        \"bandwidth\" : [0.1, 0.25, 0.5, 1, 1.5],\n",
    "        \"weight\" : [const, linear, pow2],\n",
    "        \"resolution\" : [(10,10), (20,20), (40,40), (50, 50)],\n",
    "    },\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "models_to_test = {\n",
    "    \"PBoW\" : pbow_gridsearch, \n",
    "    \"SPboW\" : spbow_gridsearch,\n",
    "    #\"SWK\" : swk_gridsearch, \n",
    "    #\"SWK_ker\" : swk_ker_gridsearch,\n",
    "    #\"Bottleneck\" : bd_gridsearch,\n",
    "    \"PersistenceImage\" : pi_gridsearch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBoW\n",
      "Fitting 5 folds for each of 2052 candidates, totalling 10260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 120 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:  6.2min\n",
      "/home/drenda/miniconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 408 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 445 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done 560 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 601 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 642 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done 685 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 773 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-1)]: Done 865 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 912 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 961 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1010 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1061 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1112 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1165 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1273 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed: 46.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1385 tasks      | elapsed: 48.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1501 tasks      | elapsed: 51.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1621 tasks      | elapsed: 55.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1682 tasks      | elapsed: 58.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1745 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1808 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1873 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1938 tasks      | elapsed: 66.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2005 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed: 70.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2141 tasks      | elapsed: 73.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2210 tasks      | elapsed: 75.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2281 tasks      | elapsed: 77.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2352 tasks      | elapsed: 79.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2425 tasks      | elapsed: 82.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2498 tasks      | elapsed: 84.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2573 tasks      | elapsed: 86.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2648 tasks      | elapsed: 89.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2725 tasks      | elapsed: 91.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2802 tasks      | elapsed: 94.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2881 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2960 tasks      | elapsed: 99.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3041 tasks      | elapsed: 101.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3122 tasks      | elapsed: 104.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3205 tasks      | elapsed: 107.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3288 tasks      | elapsed: 110.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3373 tasks      | elapsed: 112.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3458 tasks      | elapsed: 115.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3545 tasks      | elapsed: 118.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3632 tasks      | elapsed: 121.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3721 tasks      | elapsed: 124.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3810 tasks      | elapsed: 127.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3901 tasks      | elapsed: 129.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3992 tasks      | elapsed: 132.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4085 tasks      | elapsed: 135.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4178 tasks      | elapsed: 138.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4273 tasks      | elapsed: 141.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4368 tasks      | elapsed: 145.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4465 tasks      | elapsed: 148.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4562 tasks      | elapsed: 151.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4661 tasks      | elapsed: 154.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4760 tasks      | elapsed: 158.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4861 tasks      | elapsed: 161.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4962 tasks      | elapsed: 164.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5065 tasks      | elapsed: 168.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5168 tasks      | elapsed: 171.8min\n"
     ]
    }
   ],
   "source": [
    "for name, grid in models_to_test.items():\n",
    "    print(name)\n",
    "    grid_path = f\"precomputed/grid/{name}.dill\"\n",
    "    \n",
    "    out = load(grid_path)\n",
    "    if out:\n",
    "        print(\"Loaded from file\")\n",
    "        models_to_test[name] = out\n",
    "    else:\n",
    "        grid.verbose = 10\n",
    "        grid.fit(X, y)\n",
    "        save(grid, grid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid computation\n",
    "grid_path = \"precomputed/grid\"\n",
    "cv_path = \"precomputed/cv\"\n",
    "\n",
    "for filename in os.listdir(grid_path):\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    grid = load(os.path.join(grid_path, filename))\n",
    "    results = load(os.path.join(cv_path, filename))\n",
    "    \n",
    "    if not results:\n",
    "        print(\"Computing\", name)\n",
    "        model = grid.best_estimator_\n",
    "        results = cross_validate(model, X, y, cv=splits, n_jobs=-1, verbose=10)\n",
    "        save(results, os.path.join(cv_path, f\"{name}.dill\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final crossval score computation\n",
    "grid_path = \"precomputed/grid\"\n",
    "cv_path = \"precomputed/cv\"\n",
    "\n",
    "for filename in os.listdir(grid_path):\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    grid = load(os.path.join(grid_path, filename))\n",
    "    results = load(os.path.join(cv_path, filename))\n",
    "    \n",
    "    if not results:\n",
    "        print(\"Computing\", name)\n",
    "        model = grid.best_estimator_\n",
    "        results = cross_validate(model, X, y, cv=splits)\n",
    "        save(results, os.path.join(cv_path, f\"{name}.dill\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing scores\n",
    "base_path = \"precomputed/cv\"\n",
    "for filename in os.listdir(base_path):\n",
    "    path = os.path.join(base_path, filename)\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    results = load(path)\n",
    "    print(name, \"Mean scores:\")\n",
    "    df = pd.DataFrame(results)\n",
    "    print(df.mean(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing  of best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, grid in models_to_test.items():\n",
    "    print(name, \"Best parameters:\")\n",
    "    grid_params = grid.param_grid.keys()\n",
    "    model = grid.best_estimator_\n",
    "    for param_name in grid_params:\n",
    "        param = model.get_params()[param_name]\n",
    "        print(f'{param_name} :', param)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot - PBoW accuracy vs n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_points = models_to_test[\"PBoW\"].best_params_[\"Model__sampler__max_points\"] + 2000\n",
    "best_n_clusters = models_to_test[\"PBoW\"].best_params_[\"Model__cluster__n_clusters\"]\n",
    "best_weight = models_to_test[\"PBoW\"].best_params_[\"Model__sampler__weight_function\"]\n",
    "best_C = models_to_test[\"PBoW\"].best_params_[\"Predictor__C\"]\n",
    "\n",
    "result_list = []\n",
    "n_clusters_range = np.arange(10, 400, 25)\n",
    "for n_clusters in n_clusters_range:\n",
    "    print(n_clusters, end = \" \")\n",
    "    final_pipeline = Pipeline([\n",
    "        (\"pbow\",  PersistenceBow(KMeans(n_clusters, n_init=5, max_iter=300, random_state=42),\n",
    "                                sampler=RandomPDSampler(best_max_points, best_weight, random_state=42))),\n",
    "        (\"Predictor\", SVC(kernel=\"linear\",C = best_C))\n",
    "    ])\n",
    "    \n",
    "    results = cross_val_score(final_pipeline, X, y, cv=splits)\n",
    "    result_list.append(np.mean(results))\n",
    "    \n",
    "plt.plot(n_clusters_range, result_list, label=\"Accuracy score\")\n",
    "plt.xlabel(\"Components\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy vs number of components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot - PBoW accuracy vs sampler max_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_points = models_to_test[\"PBoW\"].best_params_[\"Model__sampler__max_points\"]\n",
    "best_n_clusters = models_to_test[\"PBoW\"].best_params_[\"Model__cluster__n_clusters\"]\n",
    "best_weight = models_to_test[\"PBoW\"].best_params_[\"Model__sampler__weight_function\"]\n",
    "best_C = models_to_test[\"PBoW\"].best_params_[\"Predictor__C\"]\n",
    "\n",
    "result_list = []\n",
    "max_points_range = np.arange(1000, 13000, 1000)\n",
    "for max_points in max_points_range:\n",
    "    final_pipeline = Pipeline([\n",
    "        (\"pbow\",  PersistenceBow(KMeans(best_n_clusters, n_init=1, max_iter=100, random_state=42), \n",
    "                                sampler=RandomPDSampler(max_points, best_weight, random_state=42))),\n",
    "        (\"Predictor\", SVC(kernel=\"linear\", C=best_C))\n",
    "    ])\n",
    "    \n",
    "    results = cross_val_score(final_pipeline, X, y, cv=splits, n_jobs=-1)\n",
    "    result_list.append(np.mean(results))\n",
    "    \n",
    "plt.plot(max_points_range, result_list, label=\"Accuracy score\")\n",
    "plt.xlabel(\"Max points\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy vs max_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
